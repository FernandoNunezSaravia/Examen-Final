{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FernandoNunezSaravia/Examen-Final/blob/main/Examen_Final_Python_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Alumno: Fernando Martin Nuñez Saravia"
      ],
      "metadata": {
        "id": "ZWvw3Ul246H-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problema 1"
      ],
      "metadata": {
        "id": "q7B694rzW8Ds"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9yadJ5YeGfx",
        "outputId": "1faa12c4-9dc2-4e49-ed36-2fadcc91898f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 4)\n",
            "(150,)\n",
            "(150, 1)\n",
            "-------------------------------------------------------------------------\n",
            "La matriz de confusión con el modelo SVM es:\n",
            "[[[26  0]\n",
            "  [ 0 12]]\n",
            "\n",
            " [[21  3]\n",
            "  [ 0 14]]\n",
            "\n",
            " [[26  0]\n",
            "  [ 3  9]]]\n",
            "La matriz de confusión con el modelo RF es:\n",
            "[[[26  0]\n",
            "  [ 0 12]]\n",
            "\n",
            " [[20  4]\n",
            "  [ 0 14]]\n",
            "\n",
            " [[26  0]\n",
            "  [ 4  8]]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Establezca 2 modelos de clasificación para el data Iris\n",
        "\"\"\"\n",
        "# Importamos las librerías necesarias\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "\n",
        "# Configuramos la matrix 'X' y el vector 'y'\n",
        "df_iris = datasets.load_iris()\n",
        "X = df_iris.data\n",
        "y = df_iris.target\n",
        "\n",
        "# Verificamos la dimensionalidad vectorial de la data\n",
        "print(np.shape(X))\n",
        "print(np.shape(y))\n",
        "y = np.reshape(y,(150,1))\n",
        "print(np.shape(y))\n",
        "\n",
        "# Dividimos la data en Train y Test\n",
        "Xtrain,Xtest,ytrain,ytest = tts(X,y)\n",
        "\n",
        "print (\"-------------------------------------------------------------------------\")\n",
        "\n",
        "##### MODELO SUPPORT VECTOR MACHINE (SVM)\n",
        "\n",
        "# Creamos el modelo\n",
        "svcmodel = SVC(gamma = 'scale')\n",
        "\n",
        "# Entrenamos la data\n",
        "svcmodel.fit(Xtrain,ytrain)\n",
        "\n",
        "# Validamos resultados\n",
        "ypredict_svc = svcmodel.predict(Xtest)\n",
        "matriz_svc = multilabel_confusion_matrix(ytest,ypredict_svc)\n",
        "print(\"La matriz de confusión con el modelo SVM es:\")\n",
        "print(matriz_svc)\n",
        "\n",
        "##### MODELO RANDOM FOREST (RF)\n",
        "\n",
        "# Creamos el modelo\n",
        "rfmodel = RandomForestClassifier(n_estimators = 100,random_state = 42)\n",
        "\n",
        "# Entrenamos la data\n",
        "rfmodel.fit(Xtrain,ytrain)\n",
        "\n",
        "# Validamos resultados\n",
        "ypredict_rf = rfmodel.predict(Xtest)\n",
        "matriz_rf = multilabel_confusion_matrix(ytest,ypredict_rf)\n",
        "print(\"La matriz de confusión con el modelo RF es:\")\n",
        "print(matriz_rf)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problema 2"
      ],
      "metadata": {
        "id": "D9CIyKvgW_fv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "-6oRnufgeMaT",
        "outputId": "fd93da99-5435-4b9e-d625-261ddbfe8079"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9e3feac4-4c3c-49de-a914-678a67701c26\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Suburb</th>\n",
              "      <th>Address</th>\n",
              "      <th>Rooms</th>\n",
              "      <th>Type</th>\n",
              "      <th>Price</th>\n",
              "      <th>Method</th>\n",
              "      <th>SellerG</th>\n",
              "      <th>Date</th>\n",
              "      <th>Distance</th>\n",
              "      <th>Postcode</th>\n",
              "      <th>Bedroom2</th>\n",
              "      <th>Bathroom</th>\n",
              "      <th>Car</th>\n",
              "      <th>Landsize</th>\n",
              "      <th>BuildingArea</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>CouncilArea</th>\n",
              "      <th>Lattitude</th>\n",
              "      <th>Longtitude</th>\n",
              "      <th>Regionname</th>\n",
              "      <th>Propertycount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Abbotsford</td>\n",
              "      <td>85 Turner St</td>\n",
              "      <td>2</td>\n",
              "      <td>h</td>\n",
              "      <td>1480000.0</td>\n",
              "      <td>S</td>\n",
              "      <td>Biggin</td>\n",
              "      <td>3/12/2016</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3067.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>202.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yarra</td>\n",
              "      <td>-37.7996</td>\n",
              "      <td>144.9984</td>\n",
              "      <td>Northern Metropolitan</td>\n",
              "      <td>4019.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Abbotsford</td>\n",
              "      <td>25 Bloomburg St</td>\n",
              "      <td>2</td>\n",
              "      <td>h</td>\n",
              "      <td>1035000.0</td>\n",
              "      <td>S</td>\n",
              "      <td>Biggin</td>\n",
              "      <td>4/02/2016</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3067.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>1900.0</td>\n",
              "      <td>Yarra</td>\n",
              "      <td>-37.8079</td>\n",
              "      <td>144.9934</td>\n",
              "      <td>Northern Metropolitan</td>\n",
              "      <td>4019.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Abbotsford</td>\n",
              "      <td>5 Charles St</td>\n",
              "      <td>3</td>\n",
              "      <td>h</td>\n",
              "      <td>1465000.0</td>\n",
              "      <td>SP</td>\n",
              "      <td>Biggin</td>\n",
              "      <td>4/03/2017</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3067.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>1900.0</td>\n",
              "      <td>Yarra</td>\n",
              "      <td>-37.8093</td>\n",
              "      <td>144.9944</td>\n",
              "      <td>Northern Metropolitan</td>\n",
              "      <td>4019.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Abbotsford</td>\n",
              "      <td>40 Federation La</td>\n",
              "      <td>3</td>\n",
              "      <td>h</td>\n",
              "      <td>850000.0</td>\n",
              "      <td>PI</td>\n",
              "      <td>Biggin</td>\n",
              "      <td>4/03/2017</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3067.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yarra</td>\n",
              "      <td>-37.7969</td>\n",
              "      <td>144.9969</td>\n",
              "      <td>Northern Metropolitan</td>\n",
              "      <td>4019.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Abbotsford</td>\n",
              "      <td>55a Park St</td>\n",
              "      <td>4</td>\n",
              "      <td>h</td>\n",
              "      <td>1600000.0</td>\n",
              "      <td>VB</td>\n",
              "      <td>Nelson</td>\n",
              "      <td>4/06/2016</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3067.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>Yarra</td>\n",
              "      <td>-37.8072</td>\n",
              "      <td>144.9941</td>\n",
              "      <td>Northern Metropolitan</td>\n",
              "      <td>4019.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e3feac4-4c3c-49de-a914-678a67701c26')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9e3feac4-4c3c-49de-a914-678a67701c26 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9e3feac4-4c3c-49de-a914-678a67701c26');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       Suburb           Address  ...             Regionname Propertycount\n",
              "0  Abbotsford      85 Turner St  ...  Northern Metropolitan        4019.0\n",
              "1  Abbotsford   25 Bloomburg St  ...  Northern Metropolitan        4019.0\n",
              "2  Abbotsford      5 Charles St  ...  Northern Metropolitan        4019.0\n",
              "3  Abbotsford  40 Federation La  ...  Northern Metropolitan        4019.0\n",
              "4  Abbotsford       55a Park St  ...  Northern Metropolitan        4019.0\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "\"\"\"\n",
        "Evalúa 2 modelos: Uno con PCA y otro sin PCA para el modelo de clasificación del dataset melbournhouses\n",
        "\"\"\"\n",
        "import pandas as pd \n",
        "\n",
        "df_melbournhouses = pd.read_csv(\"https://raw.githubusercontent.com/pedrorotta/PythonIntermedio2022/main/Examen/melbournehouses.csv\")\n",
        "df_melbournhouses.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problema 3"
      ],
      "metadata": {
        "id": "T8TJRBPlXCA-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "TOfuYuMYeaVM",
        "outputId": "ca326e05-9dc7-4fce-8b32-9be5838b55d2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d8ad2e69-87f8-4a99-8581-2422552176f3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>country</th>\n",
              "      <th>description</th>\n",
              "      <th>designation</th>\n",
              "      <th>points</th>\n",
              "      <th>price</th>\n",
              "      <th>province</th>\n",
              "      <th>region_1</th>\n",
              "      <th>region_2</th>\n",
              "      <th>variety</th>\n",
              "      <th>winery</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>US</td>\n",
              "      <td>This tremendous 100% varietal wine hails from ...</td>\n",
              "      <td>Martha's Vineyard</td>\n",
              "      <td>96</td>\n",
              "      <td>235.0</td>\n",
              "      <td>California</td>\n",
              "      <td>Napa Valley</td>\n",
              "      <td>Napa</td>\n",
              "      <td>Cabernet Sauvignon</td>\n",
              "      <td>Heitz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Ripe aromas of fig, blackberry and cassis are ...</td>\n",
              "      <td>Carodorum Selección Especial Reserva</td>\n",
              "      <td>96</td>\n",
              "      <td>110.0</td>\n",
              "      <td>Northern Spain</td>\n",
              "      <td>Toro</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tinta de Toro</td>\n",
              "      <td>Bodega Carmen Rodríguez</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>US</td>\n",
              "      <td>Mac Watson honors the memory of a wine once ma...</td>\n",
              "      <td>Special Selected Late Harvest</td>\n",
              "      <td>96</td>\n",
              "      <td>90.0</td>\n",
              "      <td>California</td>\n",
              "      <td>Knights Valley</td>\n",
              "      <td>Sonoma</td>\n",
              "      <td>Sauvignon Blanc</td>\n",
              "      <td>Macauley</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>US</td>\n",
              "      <td>This spent 20 months in 30% new French oak, an...</td>\n",
              "      <td>Reserve</td>\n",
              "      <td>96</td>\n",
              "      <td>65.0</td>\n",
              "      <td>Oregon</td>\n",
              "      <td>Willamette Valley</td>\n",
              "      <td>Willamette Valley</td>\n",
              "      <td>Pinot Noir</td>\n",
              "      <td>Ponzi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>France</td>\n",
              "      <td>This is the top wine from La Bégude, named aft...</td>\n",
              "      <td>La Brûlade</td>\n",
              "      <td>95</td>\n",
              "      <td>66.0</td>\n",
              "      <td>Provence</td>\n",
              "      <td>Bandol</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Provence red blend</td>\n",
              "      <td>Domaine de la Bégude</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8ad2e69-87f8-4a99-8581-2422552176f3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d8ad2e69-87f8-4a99-8581-2422552176f3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d8ad2e69-87f8-4a99-8581-2422552176f3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0 country  ...             variety                   winery\n",
              "0           0      US  ...  Cabernet Sauvignon                    Heitz\n",
              "1           1   Spain  ...       Tinta de Toro  Bodega Carmen Rodríguez\n",
              "2           2      US  ...     Sauvignon Blanc                 Macauley\n",
              "3           3      US  ...          Pinot Noir                    Ponzi\n",
              "4           4  France  ...  Provence red blend     Domaine de la Bégude\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\"\"\"\n",
        "¿Existe sobreajuste al aplicar un modelo de RF con n = 200 para el modelo de wine.csv? \n",
        "\"\"\"\n",
        "# Importamos las librerías necesarias\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Establecemos el dataframe\n",
        "df_wine = pd.read_excel(\"/content/Examen Final - Wine.xlsx\")\n",
        "display(df_wine.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Primero transfomaremos las variables categóricas en variables numéricas pues no hay suficientes variables numéricas para elaborar un modelo de regresión\n",
        "encoder = LabelEncoder()\n",
        "encode_x1 = encoder.fit_transform(df_wine['province'])\n",
        "print(encode_x1[0:10])\n",
        "encode_x2 = encoder.fit_transform(df_wine['region_1'])\n",
        "print(encode_x2[0:10])\n",
        "\"\"\"\n",
        "Parecía que había un error con los valores de la columna 'price' pues a la hora de entrenar la data me salía\n",
        "'ValueError: Input contains NotaNumber, infinity or a value too large for dtype('float64')' por eso decidí aplicarle el\n",
        "Label Encoder también y finalmente funcionó (no tiene un r2 tan bueno, pero lo considero adecuado)\n",
        "\"\"\"\n",
        "encode_y1 = encoder.fit_transform(df_wine['price'])\n",
        "print(encode_y1[0:10])\n",
        "\n",
        "# Ahora sí configuramos la matrix 'X' y el vector 'y'\n",
        "X = np.c_[encode_x1,encode_x2]\n",
        "y = np.array(encode_y1)"
      ],
      "metadata": {
        "id": "xNYWB1unUPSP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2a77870-9511-4861-ff13-75ef6c1d2cdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 51 274  51 282 313 274 274 274 282  51]\n",
            "[ 738 1070  528 1222   66 1070 1070 1070  204 1000]\n",
            "[216 106  86  61  62  69  61 106  61  56]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificamos la dimensionalidad vectorial de la data\n",
        "print(np.shape(X))\n",
        "print(np.shape(y))\n",
        "y = np.reshape(y,(len(y),1))\n",
        "print(np.shape(y))\n",
        "\n",
        "# Dividimos la data en Train y Test\n",
        "Xtrain,Xtest,ytrain,ytest = tts(X,y)\n",
        "\n",
        "# Creamos el modelo\n",
        "modeloRF = RandomForestRegressor(n_estimators = 200,random_state = 42)\n",
        "\n",
        "# Entrenamos la data\n",
        "modeloRF.fit(Xtrain,ytrain)\n",
        "\n",
        "# Evaluamos si existe sobreajuste, subajuste o el modelo está generalizado (comparamos resultados de validación y de entrenamiento)\n",
        "ypred_test = modeloRF.predict(Xtest)\n",
        "r2_test = r2_score(ytest,ypred_test)\n",
        "print(\"R2 de validación:\",r2_test)\n",
        "\n",
        "print(\"------------------------------------------------------------------\")\n",
        "\n",
        "ypred_train = modeloRF.predict(Xtrain)\n",
        "r2_train = r2_score(ytrain,ypred_train)\n",
        "print(\"R2 de entrenamiento:\",r2_train)\n",
        "\n",
        "print(\"------------------------------------------------------------------\")\n",
        "\n",
        "\"\"\"\n",
        "Respuesta: No existe sobreajuste sino mas bien se puede decir que el modelo está generalizado ya que el valor del r2 de\n",
        "validación se asemeja al valor del r2 de entrenamiento (lo cual es bueno)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "fzrUPjq7Od1U",
        "outputId": "593068f3-fa5c-4f52-a90d-d46a66cfcf8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150930, 2)\n",
            "(150930,)\n",
            "(150930, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 de validación: 0.3110522724974971\n",
            "------------------------------------------------------------------\n",
            "R2 de entrenamiento: 0.32641952288684106\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nRespuesta: No existe sobreajuste sino mas bien se puede decir que el modelo está generalizado ya que el valor del r2 de\\nvalidación se asemeja al valor del r2 de entrenamiento (lo cual es bueno)\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problema 4\n"
      ],
      "metadata": {
        "id": "G7i_vGItXEI9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNPyBdnnej01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "c0d99eb1-caba-4985-f16a-ace8fe978c46"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c84185fb-5a1f-4a51-8c69-fa2a4758b5ee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c84185fb-5a1f-4a51-8c69-fa2a4758b5ee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c84185fb-5a1f-4a51-8c69-fa2a4758b5ee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c84185fb-5a1f-4a51-8c69-fa2a4758b5ee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         id diagnosis  ...  symmetry_worst  fractal_dimension_worst\n",
              "0    842302         M  ...          0.4601                  0.11890\n",
              "1    842517         M  ...          0.2750                  0.08902\n",
              "2  84300903         M  ...          0.3613                  0.08758\n",
              "3  84348301         M  ...          0.6638                  0.17300\n",
              "4  84358402         M  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\"\"\"\n",
        "Puedes graficar un modelo de deep leraning para la dataset de breast-cancer\n",
        "\"\"\"\n",
        "# Importamos las librerías necesarias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Definimos la ruta\n",
        "breastdf = pd.read_csv(\"https://raw.githubusercontent.com/pedrorotta/PythonIntermedio2022/main/Examen/breast-cancer.csv\")\n",
        "display(breastdf.head())\n",
        "dfX = breastdf.drop(columns = ['id','diagnosis'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformamos la variable 'diagnosis' a una variable numérica pues como variable nominal no es posible crear el modelo\n",
        "Encoder = LabelEncoder()\n",
        "y = Encoder.fit_transform(breastdf['diagnosis'])\n",
        "\n",
        "# Verificamos la dimensionalidad vectorial de la data\n",
        "y = np.reshape(y,(len(y),1))\n",
        "print(y[:4])\n",
        "print(np.shape(y))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "\n",
        "# Escalamos la data para un mejor resultado\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "escalar = MinMaxScaler()\n",
        "X = np.array(dfX)\n",
        "X = escalar.fit_transform(X)\n",
        "print(X[0:4,:])\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "\n",
        "# Dividimos la data en evaluación y entrenamiento\n",
        "Xtrain,Xtest,ytrain,ytest = tts(X,y)\n",
        "\n",
        "# Creamos el modelo de clasificación de Deep Learning (primero la secuencia y luego la compilación)\n",
        "ModeloClasificador = tf.keras.Sequential([\n",
        "      tf.keras.Input(shape = (30,)),\n",
        "      tf.keras.layers.Dense(30,activation = 'relu'),\n",
        "      tf.keras.layers.Dense(60,activation = 'relu'),\n",
        "      tf.keras.layers.Dense(30,activation = 'relu'),\n",
        "      tf.keras.layers.Dense(10,activation = 'relu'),\n",
        "      tf.keras.layers.Dense(4,activation = 'relu'),\n",
        "      tf.keras.layers.Dense(2,activation = 'relu'),\n",
        "      tf.keras.layers.Dense(1,activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "ModeloClasificador.compile(loss = tf.keras.losses.binary_crossentropy,optimizer = tf.keras.optimizers.SGD(),\n",
        "                           metrics = 'accuracy')\n",
        "\n",
        "historico = ModeloClasificador.fit(Xtrain,ytrain,epochs = 700)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vye7UbwJXsuF",
        "outputId": "4fee4fcf-1bbc-42c2-a6d3-e77a1004cbcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1]\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "(569, 1)\n",
            "-----------------------------------------------------------------\n",
            "[[0.52103744 0.0226581  0.54598853 0.36373277 0.59375282 0.7920373\n",
            "  0.70313964 0.73111332 0.68636364 0.60551811 0.35614702 0.12046941\n",
            "  0.3690336  0.27381126 0.15929565 0.35139844 0.13568182 0.30062512\n",
            "  0.31164518 0.18304244 0.62077552 0.14152452 0.66831017 0.45069799\n",
            "  0.60113584 0.61929156 0.56861022 0.91202749 0.59846245 0.41886396]\n",
            " [0.64314449 0.27257355 0.61578329 0.50159067 0.28987993 0.18176799\n",
            "  0.20360825 0.34875746 0.37979798 0.14132266 0.15643672 0.08258929\n",
            "  0.12444047 0.12565979 0.11938675 0.08132304 0.0469697  0.25383595\n",
            "  0.08453875 0.0911101  0.60690146 0.30357143 0.53981772 0.43521431\n",
            "  0.34755332 0.15456336 0.19297125 0.63917526 0.23358959 0.22287813]\n",
            " [0.60149557 0.3902604  0.59574321 0.44941676 0.51430893 0.4310165\n",
            "  0.46251172 0.63568588 0.50959596 0.21124684 0.22962158 0.09430251\n",
            "  0.18037035 0.16292179 0.15083115 0.2839547  0.09676768 0.38984656\n",
            "  0.20569032 0.12700551 0.55638563 0.36007463 0.50844166 0.37450845\n",
            "  0.48358978 0.38537513 0.35974441 0.83505155 0.40370589 0.21343303]\n",
            " [0.2100904  0.36083869 0.23350149 0.10290562 0.81132075 0.81136127\n",
            "  0.5656045  0.52286282 0.77626263 1.         0.13909107 0.17587518\n",
            "  0.12665504 0.03815479 0.25145324 0.54321507 0.14295455 0.35366547\n",
            "  0.72814769 0.28720479 0.24831021 0.38592751 0.24134668 0.09400806\n",
            "  0.9154725  0.8140117  0.54864217 0.88487973 1.         0.77371114]]\n",
            "-----------------------------------------------------------------\n",
            "Epoch 1/700\n",
            "14/14 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.6268\n",
            "Epoch 2/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.6898 - accuracy: 0.6315\n",
            "Epoch 3/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.6315\n",
            "Epoch 4/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.6315\n",
            "Epoch 5/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6840 - accuracy: 0.6315\n",
            "Epoch 6/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6824 - accuracy: 0.6315\n",
            "Epoch 7/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6807 - accuracy: 0.6315\n",
            "Epoch 8/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6791 - accuracy: 0.6315\n",
            "Epoch 9/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6777 - accuracy: 0.6315\n",
            "Epoch 10/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6763 - accuracy: 0.6315\n",
            "Epoch 11/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6751 - accuracy: 0.6315\n",
            "Epoch 12/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6740 - accuracy: 0.6315\n",
            "Epoch 13/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6731 - accuracy: 0.6315\n",
            "Epoch 14/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6719 - accuracy: 0.6315\n",
            "Epoch 15/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6711 - accuracy: 0.6315\n",
            "Epoch 16/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6702 - accuracy: 0.6315\n",
            "Epoch 17/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.6315\n",
            "Epoch 18/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6688 - accuracy: 0.6315\n",
            "Epoch 19/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6681 - accuracy: 0.6315\n",
            "Epoch 20/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6675 - accuracy: 0.6315\n",
            "Epoch 21/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6668 - accuracy: 0.6315\n",
            "Epoch 22/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6663 - accuracy: 0.6315\n",
            "Epoch 23/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6657 - accuracy: 0.6315\n",
            "Epoch 24/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6652 - accuracy: 0.6315\n",
            "Epoch 25/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6647 - accuracy: 0.6315\n",
            "Epoch 26/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6642 - accuracy: 0.6315\n",
            "Epoch 27/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6639 - accuracy: 0.6315\n",
            "Epoch 28/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6635 - accuracy: 0.6315\n",
            "Epoch 29/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6631 - accuracy: 0.6315\n",
            "Epoch 30/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6627 - accuracy: 0.6315\n",
            "Epoch 31/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6624 - accuracy: 0.6315\n",
            "Epoch 32/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6621 - accuracy: 0.6315\n",
            "Epoch 33/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6618 - accuracy: 0.6315\n",
            "Epoch 34/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6614 - accuracy: 0.6315\n",
            "Epoch 35/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6611 - accuracy: 0.6315\n",
            "Epoch 36/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6609 - accuracy: 0.6315\n",
            "Epoch 37/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6607 - accuracy: 0.6315\n",
            "Epoch 38/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6606 - accuracy: 0.6315\n",
            "Epoch 39/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6603 - accuracy: 0.6315\n",
            "Epoch 40/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6601 - accuracy: 0.6315\n",
            "Epoch 41/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6599 - accuracy: 0.6315\n",
            "Epoch 42/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6597 - accuracy: 0.6315\n",
            "Epoch 43/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6595 - accuracy: 0.6315\n",
            "Epoch 44/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6593 - accuracy: 0.6315\n",
            "Epoch 45/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6591 - accuracy: 0.6315\n",
            "Epoch 46/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6589 - accuracy: 0.6315\n",
            "Epoch 47/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6588 - accuracy: 0.6315\n",
            "Epoch 48/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6587 - accuracy: 0.6315\n",
            "Epoch 49/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6585 - accuracy: 0.6315\n",
            "Epoch 50/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6584 - accuracy: 0.6315\n",
            "Epoch 51/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6583 - accuracy: 0.6315\n",
            "Epoch 52/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6581 - accuracy: 0.6315\n",
            "Epoch 53/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6580 - accuracy: 0.6315\n",
            "Epoch 54/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6578 - accuracy: 0.6315\n",
            "Epoch 55/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6577 - accuracy: 0.6315\n",
            "Epoch 56/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6576 - accuracy: 0.6315\n",
            "Epoch 57/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6575 - accuracy: 0.6315\n",
            "Epoch 58/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6573 - accuracy: 0.6315\n",
            "Epoch 59/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6572 - accuracy: 0.6315\n",
            "Epoch 60/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6571 - accuracy: 0.6315\n",
            "Epoch 61/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6570 - accuracy: 0.6315\n",
            "Epoch 62/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6569 - accuracy: 0.6315\n",
            "Epoch 63/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6568 - accuracy: 0.6315\n",
            "Epoch 64/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6566 - accuracy: 0.6315\n",
            "Epoch 65/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6566 - accuracy: 0.6315\n",
            "Epoch 66/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6565 - accuracy: 0.6315\n",
            "Epoch 67/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6563 - accuracy: 0.6315\n",
            "Epoch 68/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6562 - accuracy: 0.6315\n",
            "Epoch 69/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6562 - accuracy: 0.6315\n",
            "Epoch 70/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6561 - accuracy: 0.6315\n",
            "Epoch 71/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6559 - accuracy: 0.6315\n",
            "Epoch 72/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6558 - accuracy: 0.6315\n",
            "Epoch 73/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6557 - accuracy: 0.6315\n",
            "Epoch 74/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6556 - accuracy: 0.6315\n",
            "Epoch 75/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6555 - accuracy: 0.6315\n",
            "Epoch 76/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6554 - accuracy: 0.6315\n",
            "Epoch 77/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6553 - accuracy: 0.6315\n",
            "Epoch 78/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6552 - accuracy: 0.6315\n",
            "Epoch 79/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6550 - accuracy: 0.6315\n",
            "Epoch 80/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6549 - accuracy: 0.6315\n",
            "Epoch 81/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6548 - accuracy: 0.6315\n",
            "Epoch 82/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6546 - accuracy: 0.6315\n",
            "Epoch 83/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6545 - accuracy: 0.6315\n",
            "Epoch 84/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6543 - accuracy: 0.6315\n",
            "Epoch 85/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6541 - accuracy: 0.6315\n",
            "Epoch 86/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.6539 - accuracy: 0.6315\n",
            "Epoch 87/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6538 - accuracy: 0.6315\n",
            "Epoch 88/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6536 - accuracy: 0.6315\n",
            "Epoch 89/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.6315\n",
            "Epoch 90/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6532 - accuracy: 0.6315\n",
            "Epoch 91/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6530 - accuracy: 0.6315\n",
            "Epoch 92/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6528 - accuracy: 0.6315\n",
            "Epoch 93/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6526 - accuracy: 0.6315\n",
            "Epoch 94/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6524 - accuracy: 0.6315\n",
            "Epoch 95/700\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.6522 - accuracy: 0.6315\n",
            "Epoch 96/700\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.6519 - accuracy: 0.6315\n",
            "Epoch 97/700\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.6517 - accuracy: 0.6315\n",
            "Epoch 98/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6514 - accuracy: 0.6315\n",
            "Epoch 99/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6511 - accuracy: 0.6315\n",
            "Epoch 100/700\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.6509 - accuracy: 0.6315\n",
            "Epoch 101/700\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.6506 - accuracy: 0.6315\n",
            "Epoch 102/700\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.6503 - accuracy: 0.6315\n",
            "Epoch 103/700\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.6499 - accuracy: 0.6315\n",
            "Epoch 104/700\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.6496 - accuracy: 0.6315\n",
            "Epoch 105/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.6315\n",
            "Epoch 106/700\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.6488 - accuracy: 0.6315\n",
            "Epoch 107/700\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.6484 - accuracy: 0.6315\n",
            "Epoch 108/700\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.6479 - accuracy: 0.6315\n",
            "Epoch 109/700\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.6474 - accuracy: 0.6315\n",
            "Epoch 110/700\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.6469 - accuracy: 0.6315\n",
            "Epoch 111/700\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.6464 - accuracy: 0.6315\n",
            "Epoch 112/700\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.6459 - accuracy: 0.6315\n",
            "Epoch 113/700\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.6453 - accuracy: 0.6315\n",
            "Epoch 114/700\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.6448 - accuracy: 0.6315\n",
            "Epoch 115/700\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.6441 - accuracy: 0.6315\n",
            "Epoch 116/700\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.6435 - accuracy: 0.6315\n",
            "Epoch 117/700\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.6429 - accuracy: 0.6315\n",
            "Epoch 118/700\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.6422 - accuracy: 0.6315\n",
            "Epoch 119/700\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.6414 - accuracy: 0.6315\n",
            "Epoch 120/700\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.6407 - accuracy: 0.6315\n",
            "Epoch 121/700\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.6399 - accuracy: 0.6315\n",
            "Epoch 122/700\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.6391 - accuracy: 0.6315\n",
            "Epoch 123/700\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.6382 - accuracy: 0.6315\n",
            "Epoch 124/700\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.6373 - accuracy: 0.6315\n",
            "Epoch 125/700\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.6363 - accuracy: 0.6315\n",
            "Epoch 126/700\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.6354 - accuracy: 0.6315\n",
            "Epoch 127/700\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.6343 - accuracy: 0.6315\n",
            "Epoch 128/700\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.6332 - accuracy: 0.6315\n",
            "Epoch 129/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.6320 - accuracy: 0.6315\n",
            "Epoch 130/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6308 - accuracy: 0.6315\n",
            "Epoch 131/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.6295 - accuracy: 0.6315\n",
            "Epoch 132/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6281 - accuracy: 0.6315\n",
            "Epoch 133/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6267 - accuracy: 0.6315\n",
            "Epoch 134/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6252 - accuracy: 0.6315\n",
            "Epoch 135/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6236 - accuracy: 0.6315\n",
            "Epoch 136/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.6219 - accuracy: 0.6315\n",
            "Epoch 137/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.6201 - accuracy: 0.6315\n",
            "Epoch 138/700\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.6182 - accuracy: 0.6315\n",
            "Epoch 139/700\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.6161 - accuracy: 0.6315\n",
            "Epoch 140/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.6138 - accuracy: 0.6315\n",
            "Epoch 141/700\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.6111 - accuracy: 0.6315\n",
            "Epoch 142/700\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.6081 - accuracy: 0.6315\n",
            "Epoch 143/700\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.6049 - accuracy: 0.6315\n",
            "Epoch 144/700\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.6015 - accuracy: 0.6315\n",
            "Epoch 145/700\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.5979 - accuracy: 0.6315\n",
            "Epoch 146/700\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.5945 - accuracy: 0.6315\n",
            "Epoch 147/700\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.5909 - accuracy: 0.6315\n",
            "Epoch 148/700\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.5873 - accuracy: 0.6315\n",
            "Epoch 149/700\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.5835 - accuracy: 0.6315\n",
            "Epoch 150/700\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.5795 - accuracy: 0.6315\n",
            "Epoch 151/700\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.5754 - accuracy: 0.6315\n",
            "Epoch 152/700\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.5712 - accuracy: 0.6315\n",
            "Epoch 153/700\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.5669 - accuracy: 0.6315\n",
            "Epoch 154/700\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.5622 - accuracy: 0.6315\n",
            "Epoch 155/700\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.5576 - accuracy: 0.6315\n",
            "Epoch 156/700\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.5527 - accuracy: 0.6315\n",
            "Epoch 157/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.5478 - accuracy: 0.6315\n",
            "Epoch 158/700\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.5424 - accuracy: 0.6315\n",
            "Epoch 159/700\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.5369 - accuracy: 0.6315\n",
            "Epoch 160/700\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.5313 - accuracy: 0.6315\n",
            "Epoch 161/700\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.5255 - accuracy: 0.6315\n",
            "Epoch 162/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.5193 - accuracy: 0.6315\n",
            "Epoch 163/700\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.5132 - accuracy: 0.6315\n",
            "Epoch 164/700\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.5056 - accuracy: 0.6315\n",
            "Epoch 165/700\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.4969 - accuracy: 0.6315\n",
            "Epoch 166/700\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.4866 - accuracy: 0.6315\n",
            "Epoch 167/700\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.4746 - accuracy: 0.6315\n",
            "Epoch 168/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.6315\n",
            "Epoch 169/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.6338\n",
            "Epoch 170/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.6667\n",
            "Epoch 171/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7347\n",
            "Epoch 172/700\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.8404\n",
            "Epoch 173/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.4011 - accuracy: 0.8850\n",
            "Epoch 174/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.3883 - accuracy: 0.9178\n",
            "Epoch 175/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.3758 - accuracy: 0.9202\n",
            "Epoch 176/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.3630 - accuracy: 0.9319\n",
            "Epoch 177/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.3509 - accuracy: 0.9390\n",
            "Epoch 178/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3375 - accuracy: 0.9296\n",
            "Epoch 179/700\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.3231 - accuracy: 0.9460\n",
            "Epoch 180/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.3105 - accuracy: 0.9413\n",
            "Epoch 181/700\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.2980 - accuracy: 0.9413\n",
            "Epoch 182/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.2840 - accuracy: 0.9507\n",
            "Epoch 183/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2704 - accuracy: 0.9531\n",
            "Epoch 184/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2562 - accuracy: 0.9531\n",
            "Epoch 185/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.2443 - accuracy: 0.9601\n",
            "Epoch 186/700\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.2321 - accuracy: 0.9624\n",
            "Epoch 187/700\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.2192 - accuracy: 0.9624\n",
            "Epoch 188/700\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.2092 - accuracy: 0.9648\n",
            "Epoch 189/700\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1966 - accuracy: 0.9648\n",
            "Epoch 190/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1903 - accuracy: 0.9624\n",
            "Epoch 191/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1801 - accuracy: 0.9601\n",
            "Epoch 192/700\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1703 - accuracy: 0.9601\n",
            "Epoch 193/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1598 - accuracy: 0.9695\n",
            "Epoch 194/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1530 - accuracy: 0.9671\n",
            "Epoch 195/700\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1466 - accuracy: 0.9648\n",
            "Epoch 196/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1400 - accuracy: 0.9624\n",
            "Epoch 197/700\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1328 - accuracy: 0.9671\n",
            "Epoch 198/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1291 - accuracy: 0.9671\n",
            "Epoch 199/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1235 - accuracy: 0.9695\n",
            "Epoch 200/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1206 - accuracy: 0.9742\n",
            "Epoch 201/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1158 - accuracy: 0.9648\n",
            "Epoch 202/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1105 - accuracy: 0.9671\n",
            "Epoch 203/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1058 - accuracy: 0.9718\n",
            "Epoch 204/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0994 - accuracy: 0.9695\n",
            "Epoch 205/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0997 - accuracy: 0.9695\n",
            "Epoch 206/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0972 - accuracy: 0.9718\n",
            "Epoch 207/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0945 - accuracy: 0.9718\n",
            "Epoch 208/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0933 - accuracy: 0.9671\n",
            "Epoch 209/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0916 - accuracy: 0.9671\n",
            "Epoch 210/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0885 - accuracy: 0.9695\n",
            "Epoch 211/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0859 - accuracy: 0.9765\n",
            "Epoch 212/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0861 - accuracy: 0.9695\n",
            "Epoch 213/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0813 - accuracy: 0.9742\n",
            "Epoch 214/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0804 - accuracy: 0.9718\n",
            "Epoch 215/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0798 - accuracy: 0.9718\n",
            "Epoch 216/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0781 - accuracy: 0.9671\n",
            "Epoch 217/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0759 - accuracy: 0.9765\n",
            "Epoch 218/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0755 - accuracy: 0.9742\n",
            "Epoch 219/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0759 - accuracy: 0.9671\n",
            "Epoch 220/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0773 - accuracy: 0.9695\n",
            "Epoch 221/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0719 - accuracy: 0.9742\n",
            "Epoch 222/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0675 - accuracy: 0.9742\n",
            "Epoch 223/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0731 - accuracy: 0.9742\n",
            "Epoch 224/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 0.9789\n",
            "Epoch 225/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0689 - accuracy: 0.9718\n",
            "Epoch 226/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0706 - accuracy: 0.9789\n",
            "Epoch 227/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.9765\n",
            "Epoch 228/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.9742\n",
            "Epoch 229/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0613 - accuracy: 0.9812\n",
            "Epoch 230/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.9742\n",
            "Epoch 231/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.9765\n",
            "Epoch 232/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.9812\n",
            "Epoch 233/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.9765\n",
            "Epoch 234/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.9789\n",
            "Epoch 235/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 0.9836\n",
            "Epoch 236/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0566 - accuracy: 0.9836\n",
            "Epoch 237/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0613 - accuracy: 0.9789\n",
            "Epoch 238/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.9789\n",
            "Epoch 239/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.9812\n",
            "Epoch 240/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0569 - accuracy: 0.9789\n",
            "Epoch 241/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0556 - accuracy: 0.9812\n",
            "Epoch 242/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9812\n",
            "Epoch 243/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0564 - accuracy: 0.9836\n",
            "Epoch 244/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.9765\n",
            "Epoch 245/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.9695\n",
            "Epoch 246/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0523 - accuracy: 0.9836\n",
            "Epoch 247/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.9812\n",
            "Epoch 248/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.9789\n",
            "Epoch 249/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0565 - accuracy: 0.9859\n",
            "Epoch 250/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.9789\n",
            "Epoch 251/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9765\n",
            "Epoch 252/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9765\n",
            "Epoch 253/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9789\n",
            "Epoch 254/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0496 - accuracy: 0.9836\n",
            "Epoch 255/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.9812\n",
            "Epoch 256/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9789\n",
            "Epoch 257/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9765\n",
            "Epoch 258/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9765\n",
            "Epoch 259/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0548 - accuracy: 0.9836\n",
            "Epoch 260/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0461 - accuracy: 0.9859\n",
            "Epoch 261/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0513 - accuracy: 0.9836\n",
            "Epoch 262/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0469 - accuracy: 0.9789\n",
            "Epoch 263/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0489 - accuracy: 0.9812\n",
            "Epoch 264/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0502 - accuracy: 0.9812\n",
            "Epoch 265/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0460 - accuracy: 0.9883\n",
            "Epoch 266/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0515 - accuracy: 0.9812\n",
            "Epoch 267/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.9789\n",
            "Epoch 268/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0549 - accuracy: 0.9765\n",
            "Epoch 269/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9836\n",
            "Epoch 270/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0435 - accuracy: 0.9836\n",
            "Epoch 271/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0548 - accuracy: 0.9789\n",
            "Epoch 272/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0488 - accuracy: 0.9812\n",
            "Epoch 273/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9812\n",
            "Epoch 274/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0487 - accuracy: 0.9789\n",
            "Epoch 275/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0544 - accuracy: 0.9789\n",
            "Epoch 276/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0456 - accuracy: 0.9836\n",
            "Epoch 277/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0503 - accuracy: 0.9742\n",
            "Epoch 278/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.9789\n",
            "Epoch 279/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9789\n",
            "Epoch 280/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0439 - accuracy: 0.9836\n",
            "Epoch 281/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0494 - accuracy: 0.9789\n",
            "Epoch 282/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9836\n",
            "Epoch 283/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9812\n",
            "Epoch 284/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0423 - accuracy: 0.9836\n",
            "Epoch 285/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9812\n",
            "Epoch 286/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0405 - accuracy: 0.9836\n",
            "Epoch 287/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9836\n",
            "Epoch 288/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0436 - accuracy: 0.9812\n",
            "Epoch 289/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0426 - accuracy: 0.9812\n",
            "Epoch 290/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0446 - accuracy: 0.9836\n",
            "Epoch 291/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9812\n",
            "Epoch 292/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9789\n",
            "Epoch 293/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 0.9836\n",
            "Epoch 294/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0407 - accuracy: 0.9836\n",
            "Epoch 295/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9789\n",
            "Epoch 296/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 0.9859\n",
            "Epoch 297/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0435 - accuracy: 0.9836\n",
            "Epoch 298/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0484 - accuracy: 0.9812\n",
            "Epoch 299/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 0.9812\n",
            "Epoch 300/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0431 - accuracy: 0.9859\n",
            "Epoch 301/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 0.9859\n",
            "Epoch 302/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.9765\n",
            "Epoch 303/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0791 - accuracy: 0.9789\n",
            "Epoch 304/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0392 - accuracy: 0.9836\n",
            "Epoch 305/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9883\n",
            "Epoch 306/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0425 - accuracy: 0.9812\n",
            "Epoch 307/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9765\n",
            "Epoch 308/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9859\n",
            "Epoch 309/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0406 - accuracy: 0.9812\n",
            "Epoch 310/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0427 - accuracy: 0.9765\n",
            "Epoch 311/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0374 - accuracy: 0.9883\n",
            "Epoch 312/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 0.9859\n",
            "Epoch 313/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.9859\n",
            "Epoch 314/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0422 - accuracy: 0.9859\n",
            "Epoch 315/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0398 - accuracy: 0.9836\n",
            "Epoch 316/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0380 - accuracy: 0.9859\n",
            "Epoch 317/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0387 - accuracy: 0.9859\n",
            "Epoch 318/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9812\n",
            "Epoch 319/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 0.9883\n",
            "Epoch 320/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 0.9789\n",
            "Epoch 321/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9859\n",
            "Epoch 322/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 0.9812\n",
            "Epoch 323/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.9906\n",
            "Epoch 324/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0394 - accuracy: 0.9859\n",
            "Epoch 325/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 0.9836\n",
            "Epoch 326/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9765\n",
            "Epoch 327/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0408 - accuracy: 0.9859\n",
            "Epoch 328/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.9859\n",
            "Epoch 329/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 0.9883\n",
            "Epoch 330/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 0.9789\n",
            "Epoch 331/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0358 - accuracy: 0.9883\n",
            "Epoch 332/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0392 - accuracy: 0.9859\n",
            "Epoch 333/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0411 - accuracy: 0.9859\n",
            "Epoch 334/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9859\n",
            "Epoch 335/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 0.9836\n",
            "Epoch 336/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9789\n",
            "Epoch 337/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0347 - accuracy: 0.9836\n",
            "Epoch 338/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 0.9789\n",
            "Epoch 339/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.9883\n",
            "Epoch 340/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0430 - accuracy: 0.9812\n",
            "Epoch 341/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0454 - accuracy: 0.9859\n",
            "Epoch 342/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.9906\n",
            "Epoch 343/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0391 - accuracy: 0.9859\n",
            "Epoch 344/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 0.9883\n",
            "Epoch 345/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0374 - accuracy: 0.9906\n",
            "Epoch 346/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0459 - accuracy: 0.9812\n",
            "Epoch 347/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0394 - accuracy: 0.9859\n",
            "Epoch 348/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0399 - accuracy: 0.9859\n",
            "Epoch 349/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0319 - accuracy: 0.9883\n",
            "Epoch 350/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0394 - accuracy: 0.9812\n",
            "Epoch 351/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.9859\n",
            "Epoch 352/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.9859\n",
            "Epoch 353/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0341 - accuracy: 0.9859\n",
            "Epoch 354/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0375 - accuracy: 0.9930\n",
            "Epoch 355/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0333 - accuracy: 0.9859\n",
            "Epoch 356/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0418 - accuracy: 0.9812\n",
            "Epoch 357/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 0.9859\n",
            "Epoch 358/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0353 - accuracy: 0.9812\n",
            "Epoch 359/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9859\n",
            "Epoch 360/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0290 - accuracy: 0.9859\n",
            "Epoch 361/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 0.9906\n",
            "Epoch 362/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0323 - accuracy: 0.9883\n",
            "Epoch 363/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0352 - accuracy: 0.9859\n",
            "Epoch 364/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0369 - accuracy: 0.9906\n",
            "Epoch 365/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.9906\n",
            "Epoch 366/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0365 - accuracy: 0.9859\n",
            "Epoch 367/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0366 - accuracy: 0.9859\n",
            "Epoch 368/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0359 - accuracy: 0.9789\n",
            "Epoch 369/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0354 - accuracy: 0.9836\n",
            "Epoch 370/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 0.9906\n",
            "Epoch 371/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9859\n",
            "Epoch 372/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0383 - accuracy: 0.9859\n",
            "Epoch 373/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 0.9883\n",
            "Epoch 374/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 0.9836\n",
            "Epoch 375/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0424 - accuracy: 0.9859\n",
            "Epoch 376/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9812\n",
            "Epoch 377/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.9883\n",
            "Epoch 378/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 0.9883\n",
            "Epoch 379/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 0.9930\n",
            "Epoch 380/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9812\n",
            "Epoch 381/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0390 - accuracy: 0.9883\n",
            "Epoch 382/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0316 - accuracy: 0.9883\n",
            "Epoch 383/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0331 - accuracy: 0.9930\n",
            "Epoch 384/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9883\n",
            "Epoch 385/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.9812\n",
            "Epoch 386/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9859\n",
            "Epoch 387/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0461 - accuracy: 0.9836\n",
            "Epoch 388/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0369 - accuracy: 0.9883\n",
            "Epoch 389/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 0.9859\n",
            "Epoch 390/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0462 - accuracy: 0.9859\n",
            "Epoch 391/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0313 - accuracy: 0.9906\n",
            "Epoch 392/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 0.9789\n",
            "Epoch 393/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 0.9906\n",
            "Epoch 394/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.9836\n",
            "Epoch 395/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0421 - accuracy: 0.9859\n",
            "Epoch 396/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0356 - accuracy: 0.9836\n",
            "Epoch 397/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.9930\n",
            "Epoch 398/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0344 - accuracy: 0.9883\n",
            "Epoch 399/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 0.9906\n",
            "Epoch 400/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0385 - accuracy: 0.9859\n",
            "Epoch 401/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0311 - accuracy: 0.9859\n",
            "Epoch 402/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.9883\n",
            "Epoch 403/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0310 - accuracy: 0.9883\n",
            "Epoch 404/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0308 - accuracy: 0.9859\n",
            "Epoch 405/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9836\n",
            "Epoch 406/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0286 - accuracy: 0.9906\n",
            "Epoch 407/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 0.9836\n",
            "Epoch 408/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0337 - accuracy: 0.9883\n",
            "Epoch 409/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 0.9859\n",
            "Epoch 410/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0300 - accuracy: 0.9883\n",
            "Epoch 411/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 0.9906\n",
            "Epoch 412/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0263 - accuracy: 0.9906\n",
            "Epoch 413/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0284 - accuracy: 0.9883\n",
            "Epoch 414/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0363 - accuracy: 0.9906\n",
            "Epoch 415/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0346 - accuracy: 0.9859\n",
            "Epoch 416/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0337 - accuracy: 0.9859\n",
            "Epoch 417/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0356 - accuracy: 0.9859\n",
            "Epoch 418/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0290 - accuracy: 0.9906\n",
            "Epoch 419/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9906\n",
            "Epoch 420/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 0.9883\n",
            "Epoch 421/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.9883\n",
            "Epoch 422/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 0.9883\n",
            "Epoch 423/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0335 - accuracy: 0.9906\n",
            "Epoch 424/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0782 - accuracy: 0.9765\n",
            "Epoch 425/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0306 - accuracy: 0.9836\n",
            "Epoch 426/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0340 - accuracy: 0.9883\n",
            "Epoch 427/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0466 - accuracy: 0.9836\n",
            "Epoch 428/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0340 - accuracy: 0.9836\n",
            "Epoch 429/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0324 - accuracy: 0.9859\n",
            "Epoch 430/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0315 - accuracy: 0.9883\n",
            "Epoch 431/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.9859\n",
            "Epoch 432/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0398 - accuracy: 0.9836\n",
            "Epoch 433/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0310 - accuracy: 0.9930\n",
            "Epoch 434/700\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0281 - accuracy: 0.9906\n",
            "Epoch 435/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0309 - accuracy: 0.9883\n",
            "Epoch 436/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0346 - accuracy: 0.9836\n",
            "Epoch 437/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0316 - accuracy: 0.9883\n",
            "Epoch 438/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0310 - accuracy: 0.9883\n",
            "Epoch 439/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 0.9906\n",
            "Epoch 440/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0331 - accuracy: 0.9859\n",
            "Epoch 441/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 0.9906\n",
            "Epoch 442/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 0.9859\n",
            "Epoch 443/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0329 - accuracy: 0.9883\n",
            "Epoch 444/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0279 - accuracy: 0.9930\n",
            "Epoch 445/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0300 - accuracy: 0.9883\n",
            "Epoch 446/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0274 - accuracy: 0.9883\n",
            "Epoch 447/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0290 - accuracy: 0.9906\n",
            "Epoch 448/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0279 - accuracy: 0.9930\n",
            "Epoch 449/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0346 - accuracy: 0.9883\n",
            "Epoch 450/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9836\n",
            "Epoch 451/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0263 - accuracy: 0.9930\n",
            "Epoch 452/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0310 - accuracy: 0.9883\n",
            "Epoch 453/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0292 - accuracy: 0.9883\n",
            "Epoch 454/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 0.9906\n",
            "Epoch 455/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0291 - accuracy: 0.9906\n",
            "Epoch 456/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0246 - accuracy: 0.9930\n",
            "Epoch 457/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0285 - accuracy: 0.9859\n",
            "Epoch 458/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0293 - accuracy: 0.9883\n",
            "Epoch 459/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0320 - accuracy: 0.9859\n",
            "Epoch 460/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0313 - accuracy: 0.9859\n",
            "Epoch 461/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0270 - accuracy: 0.9836\n",
            "Epoch 462/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0315 - accuracy: 0.9906\n",
            "Epoch 463/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0283 - accuracy: 0.9883\n",
            "Epoch 464/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0304 - accuracy: 0.9883\n",
            "Epoch 465/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0348 - accuracy: 0.9836\n",
            "Epoch 466/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0338 - accuracy: 0.9883\n",
            "Epoch 467/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 0.9883\n",
            "Epoch 468/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0238 - accuracy: 0.9883\n",
            "Epoch 469/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.9906\n",
            "Epoch 470/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0263 - accuracy: 0.9906\n",
            "Epoch 471/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0250 - accuracy: 0.9906\n",
            "Epoch 472/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0250 - accuracy: 0.9930\n",
            "Epoch 473/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0303 - accuracy: 0.9883\n",
            "Epoch 474/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0300 - accuracy: 0.9859\n",
            "Epoch 475/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0270 - accuracy: 0.9906\n",
            "Epoch 476/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 0.9906\n",
            "Epoch 477/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0266 - accuracy: 0.9906\n",
            "Epoch 478/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0266 - accuracy: 0.9883\n",
            "Epoch 479/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0316 - accuracy: 0.9859\n",
            "Epoch 480/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 0.9883\n",
            "Epoch 481/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.9883\n",
            "Epoch 482/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0354 - accuracy: 0.9906\n",
            "Epoch 483/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 0.9859\n",
            "Epoch 484/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 0.9930\n",
            "Epoch 485/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0272 - accuracy: 0.9883\n",
            "Epoch 486/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0290 - accuracy: 0.9906\n",
            "Epoch 487/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.9836\n",
            "Epoch 488/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0250 - accuracy: 0.9930\n",
            "Epoch 489/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0257 - accuracy: 0.9906\n",
            "Epoch 490/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1000 - accuracy: 0.9695\n",
            "Epoch 491/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0232 - accuracy: 0.9930\n",
            "Epoch 492/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0286 - accuracy: 0.9930\n",
            "Epoch 493/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0291 - accuracy: 0.9930\n",
            "Epoch 494/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 0.9906\n",
            "Epoch 495/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0244 - accuracy: 0.9930\n",
            "Epoch 496/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0364 - accuracy: 0.9859\n",
            "Epoch 497/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0331 - accuracy: 0.9859\n",
            "Epoch 498/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0221 - accuracy: 0.9953\n",
            "Epoch 499/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0326 - accuracy: 0.9906\n",
            "Epoch 500/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0319 - accuracy: 0.9930\n",
            "Epoch 501/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0261 - accuracy: 0.9883\n",
            "Epoch 502/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0282 - accuracy: 0.9883\n",
            "Epoch 503/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 0.9859\n",
            "Epoch 504/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 0.9953\n",
            "Epoch 505/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0265 - accuracy: 0.9883\n",
            "Epoch 506/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 0.9906\n",
            "Epoch 507/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0281 - accuracy: 0.9906\n",
            "Epoch 508/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0229 - accuracy: 0.9883\n",
            "Epoch 509/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 0.9812\n",
            "Epoch 510/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0238 - accuracy: 0.9883\n",
            "Epoch 511/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 0.9859\n",
            "Epoch 512/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0287 - accuracy: 0.9906\n",
            "Epoch 513/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0253 - accuracy: 0.9930\n",
            "Epoch 514/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0287 - accuracy: 0.9883\n",
            "Epoch 515/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.9906\n",
            "Epoch 516/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0239 - accuracy: 0.9906\n",
            "Epoch 517/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0289 - accuracy: 0.9883\n",
            "Epoch 518/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0240 - accuracy: 0.9906\n",
            "Epoch 519/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0292 - accuracy: 0.9906\n",
            "Epoch 520/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 0.9883\n",
            "Epoch 521/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 0.9906\n",
            "Epoch 522/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0234 - accuracy: 0.9906\n",
            "Epoch 523/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0227 - accuracy: 0.9906\n",
            "Epoch 524/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 0.9930\n",
            "Epoch 525/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0284 - accuracy: 0.9883\n",
            "Epoch 526/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0257 - accuracy: 0.9953\n",
            "Epoch 527/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 0.9953\n",
            "Epoch 528/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0235 - accuracy: 0.9930\n",
            "Epoch 529/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0333 - accuracy: 0.9883\n",
            "Epoch 530/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0245 - accuracy: 0.9906\n",
            "Epoch 531/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0276 - accuracy: 0.9859\n",
            "Epoch 532/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 0.9930\n",
            "Epoch 533/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0290 - accuracy: 0.9883\n",
            "Epoch 534/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.9883\n",
            "Epoch 535/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 0.9930\n",
            "Epoch 536/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0272 - accuracy: 0.9883\n",
            "Epoch 537/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0242 - accuracy: 0.9883\n",
            "Epoch 538/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 0.9883\n",
            "Epoch 539/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0264 - accuracy: 0.9883\n",
            "Epoch 540/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.9953\n",
            "Epoch 541/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 0.9930\n",
            "Epoch 542/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 0.9953\n",
            "Epoch 543/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.9836\n",
            "Epoch 544/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0332 - accuracy: 0.9836\n",
            "Epoch 545/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 0.9883\n",
            "Epoch 546/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 0.9812\n",
            "Epoch 547/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 0.9930\n",
            "Epoch 548/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0270 - accuracy: 0.9883\n",
            "Epoch 549/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0247 - accuracy: 0.9930\n",
            "Epoch 550/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9906\n",
            "Epoch 551/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0253 - accuracy: 0.9930\n",
            "Epoch 552/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 0.9930\n",
            "Epoch 553/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0230 - accuracy: 0.9883\n",
            "Epoch 554/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0242 - accuracy: 0.9883\n",
            "Epoch 555/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 0.9906\n",
            "Epoch 556/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 0.9883\n",
            "Epoch 557/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0230 - accuracy: 0.9906\n",
            "Epoch 558/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 0.9930\n",
            "Epoch 559/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0240 - accuracy: 0.9883\n",
            "Epoch 560/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0313 - accuracy: 0.9836\n",
            "Epoch 561/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 0.9930\n",
            "Epoch 562/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 0.9930\n",
            "Epoch 563/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0373 - accuracy: 0.9859\n",
            "Epoch 564/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0301 - accuracy: 0.9859\n",
            "Epoch 565/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 0.9859\n",
            "Epoch 566/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0232 - accuracy: 0.9859\n",
            "Epoch 567/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 0.9930\n",
            "Epoch 568/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0221 - accuracy: 0.9930\n",
            "Epoch 569/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 0.9883\n",
            "Epoch 570/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0446 - accuracy: 0.9836\n",
            "Epoch 571/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1001 - accuracy: 0.9742\n",
            "Epoch 572/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 0.9906\n",
            "Epoch 573/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0221 - accuracy: 0.9930\n",
            "Epoch 574/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 0.9953\n",
            "Epoch 575/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0238 - accuracy: 0.9859\n",
            "Epoch 576/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 0.9977\n",
            "Epoch 577/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 0.9883\n",
            "Epoch 578/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0228 - accuracy: 0.9930\n",
            "Epoch 579/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9906\n",
            "Epoch 580/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 0.9930\n",
            "Epoch 581/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0264 - accuracy: 0.9859\n",
            "Epoch 582/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0179 - accuracy: 0.9906\n",
            "Epoch 583/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0228 - accuracy: 0.9906\n",
            "Epoch 584/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0337 - accuracy: 0.9836\n",
            "Epoch 585/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 0.9930\n",
            "Epoch 586/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0353 - accuracy: 0.9883\n",
            "Epoch 587/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0272 - accuracy: 0.9883\n",
            "Epoch 588/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0416 - accuracy: 0.9836\n",
            "Epoch 589/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0248 - accuracy: 0.9930\n",
            "Epoch 590/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 0.9953\n",
            "Epoch 591/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 0.9930\n",
            "Epoch 592/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 0.9930\n",
            "Epoch 593/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9906\n",
            "Epoch 594/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 0.9930\n",
            "Epoch 595/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 0.9930\n",
            "Epoch 596/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 0.9906\n",
            "Epoch 597/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0369 - accuracy: 0.9836\n",
            "Epoch 598/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 0.9953\n",
            "Epoch 599/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0227 - accuracy: 0.9906\n",
            "Epoch 600/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 0.9953\n",
            "Epoch 601/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.9742\n",
            "Epoch 602/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 0.9930\n",
            "Epoch 603/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0271 - accuracy: 0.9859\n",
            "Epoch 604/700\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0240 - accuracy: 0.9906\n",
            "Epoch 605/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 0.9906\n",
            "Epoch 606/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0200 - accuracy: 0.9930\n",
            "Epoch 607/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 0.9906\n",
            "Epoch 608/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0311 - accuracy: 0.9836\n",
            "Epoch 609/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9953\n",
            "Epoch 610/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0227 - accuracy: 0.9906\n",
            "Epoch 611/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 0.9906\n",
            "Epoch 612/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0253 - accuracy: 0.9859\n",
            "Epoch 613/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9836\n",
            "Epoch 614/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0320 - accuracy: 0.9883\n",
            "Epoch 615/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0187 - accuracy: 0.9906\n",
            "Epoch 616/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0357 - accuracy: 0.9906\n",
            "Epoch 617/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0239 - accuracy: 0.9883\n",
            "Epoch 618/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 0.9906\n",
            "Epoch 619/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 0.9930\n",
            "Epoch 620/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 0.9930\n",
            "Epoch 621/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 0.9883\n",
            "Epoch 622/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0265 - accuracy: 0.9883\n",
            "Epoch 623/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0241 - accuracy: 0.9883\n",
            "Epoch 624/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9742\n",
            "Epoch 625/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0215 - accuracy: 0.9930\n",
            "Epoch 626/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 0.9953\n",
            "Epoch 627/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0334 - accuracy: 0.9859\n",
            "Epoch 628/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0308 - accuracy: 0.9836\n",
            "Epoch 629/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0311 - accuracy: 0.9836\n",
            "Epoch 630/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0237 - accuracy: 0.9883\n",
            "Epoch 631/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 0.9930\n",
            "Epoch 632/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 0.9906\n",
            "Epoch 633/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0237 - accuracy: 0.9906\n",
            "Epoch 634/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0192 - accuracy: 0.9930\n",
            "Epoch 635/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0192 - accuracy: 0.9930\n",
            "Epoch 636/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0229 - accuracy: 0.9883\n",
            "Epoch 637/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 0.9906\n",
            "Epoch 638/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 0.9906\n",
            "Epoch 639/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0332 - accuracy: 0.9812\n",
            "Epoch 640/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 0.9906\n",
            "Epoch 641/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 0.9883\n",
            "Epoch 642/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0829 - accuracy: 0.9695\n",
            "Epoch 643/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 0.9930\n",
            "Epoch 644/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 0.9930\n",
            "Epoch 645/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0237 - accuracy: 0.9883\n",
            "Epoch 646/700\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0231 - accuracy: 0.9906\n",
            "Epoch 647/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9930\n",
            "Epoch 648/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 0.9930\n",
            "Epoch 649/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0280 - accuracy: 0.9906\n",
            "Epoch 650/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 0.9930\n",
            "Epoch 651/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0900 - accuracy: 0.9554\n",
            "Epoch 652/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 0.9906\n",
            "Epoch 653/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9883\n",
            "Epoch 654/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 0.9883\n",
            "Epoch 655/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 0.9883\n",
            "Epoch 656/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.9859\n",
            "Epoch 657/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0329 - accuracy: 0.9836\n",
            "Epoch 658/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9930\n",
            "Epoch 659/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 0.9953\n",
            "Epoch 660/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9883\n",
            "Epoch 661/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0191 - accuracy: 0.9953\n",
            "Epoch 662/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0291 - accuracy: 0.9836\n",
            "Epoch 663/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 0.9930\n",
            "Epoch 664/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 0.9953\n",
            "Epoch 665/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 0.9953\n",
            "Epoch 666/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9953\n",
            "Epoch 667/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0256 - accuracy: 0.9859\n",
            "Epoch 668/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0310 - accuracy: 0.9906\n",
            "Epoch 669/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0313 - accuracy: 0.9883\n",
            "Epoch 670/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 0.9906\n",
            "Epoch 671/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 0.9953\n",
            "Epoch 672/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 0.9953\n",
            "Epoch 673/700\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0198 - accuracy: 0.9906\n",
            "Epoch 674/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0407 - accuracy: 0.9859\n",
            "Epoch 675/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 0.9930\n",
            "Epoch 676/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 0.9953\n",
            "Epoch 677/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 0.9883\n",
            "Epoch 678/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.9930\n",
            "Epoch 679/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 0.9836\n",
            "Epoch 680/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0309 - accuracy: 0.9812\n",
            "Epoch 681/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 0.9953\n",
            "Epoch 682/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9930\n",
            "Epoch 683/700\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0213 - accuracy: 0.9930\n",
            "Epoch 684/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0281 - accuracy: 0.9883\n",
            "Epoch 685/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0248 - accuracy: 0.9930\n",
            "Epoch 686/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9906\n",
            "Epoch 687/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 0.9883\n",
            "Epoch 688/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 0.9977\n",
            "Epoch 689/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 0.9906\n",
            "Epoch 690/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 0.9953\n",
            "Epoch 691/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0258 - accuracy: 0.9883\n",
            "Epoch 692/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 0.9953\n",
            "Epoch 693/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0219 - accuracy: 0.9906\n",
            "Epoch 694/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9930\n",
            "Epoch 695/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0315 - accuracy: 0.9859\n",
            "Epoch 696/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.9930\n",
            "Epoch 697/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 0.9930\n",
            "Epoch 698/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9930\n",
            "Epoch 699/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.9930\n",
            "Epoch 700/700\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 0.9906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"-----------------------------------------------------------------\")\n",
        "\n",
        "# Graficamos la función de costo\n",
        "pd.DataFrame(historico.history).plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "Eapb8k9QbLoq",
        "outputId": "e9b97602-3aee-42cd-88c8-3ab4641ee202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7ccdc898d0>"
            ]
          },
          "metadata": {},
          "execution_count": 234
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problema 5"
      ],
      "metadata": {
        "id": "V2BNWr2jXFlk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNndw4yBesID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d05d012d-02fa-4102-de46-c77fbeab738b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Escribe 'I' para ingresar la ruta de su imagen o cualquier otro comando para cerrar el programa: I\n",
            "Ingrese la ruta de su imagen: /content/gato.jpg\n",
            "(3686400,)\n",
            "Escribe 'I' para ingresar la ruta de su imagen o cualquier otro comando para cerrar el programa: I\n",
            "Ingrese la ruta de su imagen: /content/gatos-gestos-m.jpg\n",
            "(3686400,)\n",
            "(750000,)\n",
            "Escribe 'I' para ingresar la ruta de su imagen o cualquier otro comando para cerrar el programa: I\n",
            "Ingrese la ruta de su imagen: /content/gato-marron_0.jpg\n",
            "(3686400,)\n",
            "(750000,)\n",
            "(2924100,)\n",
            "Escribe 'I' para ingresar la ruta de su imagen o cualquier otro comando para cerrar el programa: X\n",
            "Saliendo del programa\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Crea una función que aplane la ruta de una imágen\n",
        "\"\"\"\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def AplanarImagen():\n",
        "  images = []\n",
        "  decision = input(\"Escribe 'I' para ingresar la ruta de su imagen o cualquier otro comando para cerrar el programa: \")\n",
        "  while decision == 'I':\n",
        "    ruta = input(\"Ingrese la ruta de su imagen: \")\n",
        "    images.append(plt.imread(ruta))\n",
        "    for image in images:\n",
        "      vector = image.flatten()\n",
        "      print(np.shape(vector))\n",
        "    decision = input(\"Escribe 'I' para ingresar la ruta de su imagen o cualquier otro comando para cerrar el programa: \")\n",
        "  print(\"Saliendo del programa\")\n",
        "\n",
        "AplanarImagen()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Examen Final Python 2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}